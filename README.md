# Proyecto-Dip.-Ciencia-de-datos
Archivos fuentes del proyecto de ciencia de datos, incluye tambien el notebook y el tableau
# üéì Proyecto de Ciencia de Datos: An√°lisis y predicci√≥n del bajo rendimiento acad√©mico en la unidad educativa San Jos√© Obrero

### Autor: Limberg Villca Coraite
### Universidad: Universidad Mayor de San Sim√≥n
### Repositorio: [GitHub - LimbergVillcaCoraite/Proyecto-Dip.-Ciencia-de-datos](https://github.com/LimbergVillcaCoraite/Proyecto-Dip.-Ciencia-de-datos.git)

## üìä Descripci√≥n General
Este proyecto aplica t√©cnicas de *machine learning* para predecir la probabilidad de que un estudiante repruebe, utilizando exclusivamente datos acad√©micos. Se evaluaron varios modelos, optimizados mediante b√∫squeda de hiperpar√°metros, para identificar el que ofrece el mejor rendimiento predictivo.

---

## üîß Tecnolog√≠as y Librer√≠as Utilizadas
- Python 3.9+
- Jupyter Notebook
- Scikit-learn
- Pandas & NumPy
- Matplotlib & Seaborn

---
---
## ‚úÖ Modelos probados
- Logistic Regression
- XGBoost
- XGBoost
- Gradient Boosting
- SVM
- MLP
- LightGBM
- CatBoost
---

## üóÇÔ∏è Estructura del Proyecto
```
proyecto_ciencia_datos/
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/README.md
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/requirements.txt
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/Codigo fuente
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/Documentos
‚îú‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/Gr√°ficos
‚îî‚îÄ‚îÄ /Proyecto-Dip.-Ciencia-de-datos/data-source/

```

---

## üöÄ Instrucciones para Ejecutar el Proyecto

1. **Clona el repositorio**
```bash
git https://github.com/LimbergVillcaCoraite/Proyecto-Dip.-Ciencia-de-datos.git
cd Proyecto-Dip.-Ciencia-de-datos.git
```

2. **Crea y activa un entorno virtual** (opcional pero recomendado)
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instala las dependencias necesarias**
```bash
pip install -r requirements.txt
```

4. **Abre el cuaderno Jupyter**
```bash
jupyter notebook ./Codigo fuente/proyecto_ciencia_de_datos.ipynb

**Tambi√©n puedes ejecutarlo directamente en Google Colab:**  
üîó [https://colab.research.google.com/drive/1zkWX89JU6IW6N8T1Umz4BIQFn2K_l-LI](https://colab.research.google.com/drive/1zkWX89JU6IW6N8T1Umz4BIQFn2K_l-LI?usp=sharing)

```

---

## üß¨ L√≥gica del Proyecto
- Se divide el conjunto de datos en entrenamiento y prueba.
- Se prueban m√∫ltiples modelos: Logistic Regression, Random Forest, XGBoost, Gradient Boosting, SVM, MLP, LightGBM y CatBoost.
- Se realiza *Grid Search* con validaci√≥n cruzada para afinar los hiperpar√°metros (‚Üí `param_grids`).
- Se elige el mejor modelo seg√∫n el F1-score ponderado.
- Se analizan m√©tricas como Precisi√≥n, Recall y se visualiza la matriz de confusi√≥n.

---

## üìâ Resultados Clave
- Alta precisi√≥n en la predicci√≥n de estudiantes aprobados.
- Menor rendimiento en la detecci√≥n de estudiantes reprobados.
- Se sugiere que esta debilidad puede deberse a la falta de variables socioecon√≥micas, familiares o emocionales en el conjunto de datos.

---

## üíº Recomendaciones
- Incluir variables no acad√©micas para mejorar la capacidad predictiva del modelo.
- Ajustar los hiperpar√°metros en `param_grids` seg√∫n las necesidades del problema.
- Probar t√©cnicas de *feature engineering* o *ensembles* avanzados.

---

## üí¨ Contacto
¬øTienes preguntas o sugerencias? Abre un *issue* o cont√°ctame v√≠a GitHub.

---

> "Un buen modelo no solo aprende de los datos, tambi√©n cuestiona lo que falta en ellos."
